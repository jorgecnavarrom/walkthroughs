{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing tutorial\n",
    "\n",
    "## Preamble\n",
    "\n",
    "The goal of this notebook is to walk you through one of many possible ways of \n",
    "parsing a GFF3 file.\n",
    "\n",
    "A few notes about this notebook:\n",
    "\n",
    "- You can run the **code cells**. I recommend running them one by one using \n",
    "`shift` + `enter`.\n",
    "- You would typically use `sys`'s `argv` module to input the program's \n",
    "arguments, but here they will be hardcoded due to the nature of the notebook.\n",
    "- This also means that the code won't have the typical structure, but remember\n",
    "that your code should look like this:\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"\n",
    "Describe what your program does and how to run it. Also put your name here\n",
    "\"\"\"\n",
    "\n",
    "from sys import argv\n",
    "\n",
    "def main():\n",
    "    # here you would put calls to each of your functions\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A GFF3 parser\n",
    "\n",
    "A GFF3 (Generic Feature Format Version 3) file contains annotations for a \n",
    "genomic sequence. These include genes, mRNA, coding sequence (CDS), exons and\n",
    "other features.\n",
    "\n",
    "The file that we will work on also contains the DNA sequence itself (though this\n",
    "is valid, the DNA sequence is found in a separate fasta file). This data is a \n",
    "subset from an assembly of [*Catharanthus roseus*](https://www.ncbi.nlm.nih.gov/labs/data-hub/genome/GCA_000949345.1/), \n",
    "a plant from which the anti-cancer drug [vinblastine](https://en.wikipedia.org/wiki/Vinblastine) \n",
    "and [vincristine](https://en.wikipedia.org/wiki/Vincristine) are extracted.\n",
    "\n",
    "The goals of this exercise are:\n",
    "\n",
    "* **Create a fasta file with the translations of all the coding sequences**\n",
    "* **Calculate which percentage of the total sequence is coding**\n",
    "\n",
    "We will go through the first steps of parsing the file so that you end up with\n",
    "a data structure that will allow you to have the required output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The input data\n",
    "\n",
    "**STOP** ✋ First, let's take a look at the file. You can download it \n",
    "[here](https://drive.google.com/file/d/1q_vny3l-3qjhwjO5_9_PLHeU3FGMOFvW/view?usp=sharing).\n",
    "\n",
    "Scroll down to the end. What do you see? How many different sections does it \n",
    "have? Is there a clear way of separating each section/subsection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The GFF3 structure: Part 1\n",
    "\n",
    "Here, we start with a header that has the version of the format used, followed\n",
    "by a tab-delimited section with the actual annotations:\n",
    "\n",
    "```\n",
    "##gff-version 3\n",
    "cro_scaffold_3066516\tmaker\tgene\t31108\t33451\t.\t+\t.\tID=CRO_004871;Name=CRO_004871\n",
    "cro_scaffold_3066516\tmaker\tmRNA\t31108\t33451\t.\t+\t.\tID=CRO_T004871;Name=CRO_T004871;Parent=CRO_004871\n",
    "cro_scaffold_3066516\tmaker\texon\t31108\t31466\t.\t+\t.\tParent=CRO_T004871\n",
    "cro_scaffold_3066516\tmaker\texon\t31563\t31655\t.\t+\t.\tParent=CRO_T004871\n",
    "cro_scaffold_3066516\tmaker\texon\t31779\t31991\t.\t+\t.\tParent=CRO_T004871\n",
    "cro_scaffold_3066516\tmaker\texon\t32088\t32267\t.\t+\t.\tParent=CRO_T004871\n",
    "cro_scaffold_3066516\tmaker\texon\t32376\t33451\t.\t+\t.\tParent=CRO_T004871\n",
    "cro_scaffold_3066516\tmaker\tfive_prime_UTR\t31108\t31169\t.\t+\t.\tParent=CRO_T004871\n",
    "cro_scaffold_3066516\tmaker\tCDS\t31170\t31466\t.\t+\t0\tParent=CRO_T004871\n",
    "cro_scaffold_3066516\tmaker\tCDS\t31563\t31655\t.\t+\t0\tParent=CRO_T004871\n",
    "cro_scaffold_3066516\tmaker\tCDS\t31779\t31991\t.\t+\t0\tParent=CRO_T004871\n",
    "cro_scaffold_3066516\tmaker\tCDS\t32088\t32267\t.\t+\t0\tParent=CRO_T004871\n",
    "cro_scaffold_3066516\tmaker\tCDS\t32376\t33335\t.\t+\t0\tParent=CRO_T004871\n",
    "cro_scaffold_3066516\tmaker\tthree_prime_UTR\t33336\t33451\t.\t+\t.\tParent=CRO_T004871\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The GFF3 structure: Part 2\n",
    "\n",
    "At the bottom of the file, we have what looks like a normal fasta file:\n",
    "```\n",
    "...\n",
    "cro_scaffold_3069583\tmaker\texon\t103062\t103433\t.\t-\t.\tParent=CRO_T020549\n",
    "cro_scaffold_3069583\tmaker\tCDS\t103062\t103433\t.\t-\t0\tParent=CRO_T020549\n",
    "##FASTA\n",
    ">cro_scaffold_3069583\n",
    "GGTCCAAAATCCAATATTGTGAATAATTGTTTTCGACACGCAACATAAAATCCTTATTAAACAAACAAAAGTTGATAAAA\n",
    "AATAATATATTTTATTAGGATGATCTAGGAAAATAATTGAGTATAGTTCCTAGGATGGTAGGAAATTAATAATAATACCC\n",
    "GAAAATAAATGATATTAACAATAACATAACTATAAATAATAAACATGTCATATCACCGTAGCTGTCATGAAAATATTTTA\n",
    "CCATCAAAATTTCTCAAAAATAAAATAAGAAATAATTAAACTATATACTTAAGATTATGATGTAAATAGTTTTTCATTAT\n",
    "ATATATATCAAATATCATGATTGGCAAACCACTTTTTTTTTTTTTTTTTTTTTAAGTCTCCACTTGGTTATGGTACAAAA\n",
    "...\n",
    "```\n",
    "\n",
    "Importantly, we see a clear separator for the two main sections: the string\n",
    "'`##FASTA`'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Planning\n",
    "\n",
    "Now that we have taken a look at the file we'll work with, we have to decide\n",
    "which data structure we will use to store our data. Thinking on this now will\n",
    "guide the building of the code that follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The sequence data\n",
    "\n",
    "The bottom part is easier to think about. As we will need to retrieve the DNA\n",
    "sequences to translate them, and these all have a contig label (and moreover, \n",
    "this label is unique!), the easiest data structure here is a dictionary:\n",
    "\n",
    "```python\n",
    "fasta['contig label'] -> \"str\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The annotation data\n",
    "\n",
    "This part is clearly more complicated. Let's start with what kind of data we \n",
    "need in order to answer the exercise. \n",
    "\n",
    "The first task consists in producing the translations of all coding sequences.\n",
    "This means we need to take the right contig. Conveniently, this is indicated\n",
    "in the **first column**, where the contig labels (must!) match the ones in the \n",
    "fasta section. \n",
    "\n",
    "The type of feature that we need is the coding sequence, or **CDS**. As a \n",
    "reminder, see the full gene structure from this image from [Wikipedia](https://en.wikipedia.org/wiki/Gene_structure#Eukaryotes)\n",
    "(we need the subsequences corresponding to the red parts):\n",
    "\n",
    "![eukaryotic gene structure](Gene_structure_eukaryote_2_annotated.png)\n",
    "\n",
    "The type of feature is annotated in the **third column**. For any given \n",
    "transcript, there may be multiple CDS regions indicated, which represent the \n",
    "coding regions within multiple exons.\n",
    "\n",
    "We also need, of course, the actual coordinates, which are stored in the **4th\n",
    "and 5th columns** (are they 0- or 1-based indexed? see [here](https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md#description-of-the-format) for the answer)\n",
    "\n",
    "Another important piece of information is the strand that the transcript is in,\n",
    "which is stored in the **7th column**.\n",
    "\n",
    "If we only filtered all the \"CDS\"-containing lines, it would be impossible to\n",
    "know which one(s) belong to the same transcript. For this reason, we also need\n",
    "the information in the **9th column**, which will contains the transcript ID\n",
    "that we need to group the coordinates.\n",
    "\n",
    "To wrap this up, see this annotated figure of the gff file:\n",
    "\n",
    "![annotation section](annotation_section.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data structures\n",
    "\n",
    "How to store this data? The coordinates are the easiest as they won't be changed\n",
    "and a tuple containing both of them as integers is an obvious choice:\n",
    "\n",
    "```python\n",
    "coordinate -> tuple([start:int, end:int])\n",
    "```\n",
    "\n",
    "For the rest, there are many options. One of them is having a dictionary linking\n",
    "contigs to transcripts:\n",
    "\n",
    "```python\n",
    "annotations['contig label'] -> list('transcript label 1', 'transcript label 2', ...)\n",
    "```\n",
    "\n",
    "but then we'd need another structure to link the transcript labels to their \n",
    "coordinates.\n",
    "\n",
    "A general advice is to always use as few structures as possible. Moreover, it\n",
    "would be convenient to see the output fasta writer function as:\n",
    "\n",
    "```python\n",
    "# pseudocode:\n",
    "with open(\"translation.fasta\", \"w\") as res:\n",
    "    for every contig label:\n",
    "        # obtain contig sequence here\n",
    "        for every transcript label:\n",
    "            translation = get_translation(contig_sequence, coordinates linked to transcript)\n",
    "            # write transcript label + translation to `res`\n",
    "```\n",
    "\n",
    "Here, data would have a clear hierarchy:\n",
    "\n",
    "```\n",
    "hierarchy: contig label -> transcript label -> coordinates -> start,stop\n",
    "```\n",
    "\n",
    "This lays out a nested data structure:\n",
    "```python\n",
    "# 'CDS' is a tuple with the coding region coordinates within one exon as integers\n",
    "CDS -> tuple([start:int, end:int])\n",
    "\n",
    "# 'coordinates' is a list of CDSs belonging to a given transcript\n",
    "coordinates -> [CDS_1, CDS_2, ...]\n",
    "\n",
    "# 'transcripts' is a dictionary linking transcript labels to lists of CDSs \n",
    "# belonging to that transcript\n",
    "transcripts['transcipt label i'] -> coordinates_i\n",
    "\n",
    "# the main data structure is also a dictionary, holding all of the transcripts \n",
    "# with their CDSs for a given contig. (In this file, there are only two contigs)\n",
    "main_dictionary['contig label j'] -> transcripts_contig_j\n",
    "```\n",
    "\n",
    "There's one thing missing: the strand information. We do need this information\n",
    "when we translate the sequences, to know if we need to first do the reverse\n",
    "complement. Here, the easiest would be to keep this information elsewhere, in\n",
    "its own dictionary:\n",
    "\n",
    "```python\n",
    "strand['transcript label'] -> str\n",
    "```\n",
    "\n",
    "Now we are ready to begin our program... although we haven't discussed anything\n",
    "related to the second task: calculating the percentage of sequence that is \n",
    "coding. Think: Can we do this with the current data structures?\n",
    "\n",
    "With all of these in mind, here is the skeleton of our parsing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the definition of the function, you can indicate the data types of the \n",
    "#   arguments and returns. This is not enforced by the Python interpreter but\n",
    "#   can be used by other tools.\n",
    "def gff_parser(filename: str) -> tuple([dict, dict]):\n",
    "    \"\"\"Parses a GFF3 file\n",
    "    \n",
    "    Parameters:\n",
    "    ---\n",
    "    filename: str\n",
    "        Name of the GFF3 file\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    A tuple with two elements:\n",
    "        dict: key=contig label, value=a DNA string\n",
    "        dict: key=transcript label, value=a list of tuples representing the\n",
    "            coordinates of each CDS\n",
    "    \"\"\"\n",
    "\n",
    "    fasta = {}\n",
    "    annotation = {}\n",
    "    strand = {}\n",
    "\n",
    "    # [PARSING ALGORITHM HERE]\n",
    "                \n",
    "    return fasta, annotation, strand\n",
    "\n",
    "fasta_data, annotation_data, strand_data = gff_parser(\"Catharanthus.gff3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part three: the parser\n",
    "\n",
    "The main logic step is to divide the processing of the fasta section and the \n",
    "annotation section. For this I will use a function when I reach the '`##FASTA`'\n",
    "keyword. The function currently looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gff_parser(filename: str) -> tuple([dict, dict]):\n",
    "    \"\"\"Parses a GFF3 file\n",
    "    \n",
    "    Parameters:\n",
    "    ---\n",
    "    filename: str\n",
    "        Name of the GFF3 file\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    A tuple with two elements:\n",
    "        dict: key=contig label, value=a DNA string\n",
    "        dict: key=transcript label, value=a list of tuples representing the\n",
    "            coordinates of each CDS\n",
    "    \"\"\"\n",
    "\n",
    "    fasta = {}\n",
    "    annotation = {}\n",
    "    strand = {}\n",
    "\n",
    "    # parsing algorithm\n",
    "    with open(filename) as gff:\n",
    "        for line in gff:\n",
    "            if line.startswith(\"##FASTA\"):\n",
    "                # [LAUNCH FUNCTION TO PARSE FASTA SECTION]\n",
    "                continue\n",
    "            else:\n",
    "                # [IMPLEMENT LOGIC FOR PARSING ANNOTATION SECTION]\n",
    "                continue\n",
    "                \n",
    "    return fasta, annotation, strand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to implement the fasta-parsing logic directly in `gff_parser`.\n",
    "For that we could define a flag that would be activated when we reach the\n",
    "separator:\n",
    "\n",
    "```python\n",
    "in_fasta_section = False\n",
    "\n",
    "with open(filename) as gff:\n",
    "    for line in gff:\n",
    "        if in_fasta_section:\n",
    "            # [IMPLEMENT LOGIC FOR PARSING FASTA SECTION DIRECTLY]\n",
    "            continue\n",
    "        else:\n",
    "            # Activate the flag when separator is found. After that we\n",
    "            # won't enter this section again\n",
    "            if line.startswith(\"##FASTA\"):\n",
    "                in_fasta_section = True\n",
    "                continue\n",
    "\n",
    "            # [IMPLEMENT LOGIC FOR PARSING ANNOTATION SECTION]\n",
    "```\n",
    "\n",
    "For convenience (and clarity), I will use a separate function that takes the \n",
    "[file object](https://docs.python.org/3.11/tutorial/inputoutput.html#reading-and-writing-files) \n",
    "returned by `open()`. I'm using the fact that the file is still opened and we\n",
    "can continue looping lines from the *current position*. Attention! This means \n",
    "that we should call that function immediately after finding the section \n",
    "separator, before the next line in the file is read!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gff_parser(filename: str) -> tuple([dict, dict]):\n",
    "    \"\"\"Parses a GFF3 file\n",
    "    \n",
    "    Parameters:\n",
    "    ---\n",
    "    filename: str\n",
    "        Name of the GFF3 file\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    A tuple with two elements:\n",
    "        dict: key=contig label, value=a DNA string\n",
    "        dict: key=transcript label, value=a list of tuples representing the\n",
    "            coordinates of each CDS\n",
    "    \"\"\"\n",
    "\n",
    "    fasta = {}\n",
    "    annotation = {}\n",
    "    strand = {}\n",
    "\n",
    "    # parsing algorithm\n",
    "    with open(filename) as gff:\n",
    "        for line in gff:\n",
    "            if line.startswith(\"##FASTA\"):\n",
    "                # Launch a function that parses the fasta section\n",
    "                fasta = parse_fasta(gff)\n",
    "            else:\n",
    "                # [IMPLEMENT LOGIC FOR PARSING ANNOTATION SECTION]\n",
    "                continue\n",
    "                \n",
    "    return fasta, annotation, strand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "⚠️ Warning! This assumes that we won't find another annotation section. Always \n",
    "check your input file and, if possible, read documentation about the format!\n",
    "\n",
    "As we said, we will store the DNA sequence in a dictionary. A possible \n",
    "optimization here would be to only include in the dictionary the sequences that\n",
    "we actually have from the annotation section.\n",
    "\n",
    "Another thing to consider is how big are the input files. For small files, \n",
    "taking the complete data into a dictionary is not a big issue, but for \n",
    "assemblies/projects with many/large records (see for example [this newer \n",
    "assembly](https://www.ncbi.nlm.nih.gov/labs/data-hub/genome/GCA_024505715.1/)\n",
    "of the same organism!), it would be a good idea to refactor this code to only \n",
    "yield the sequences we need, when we need them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fasta parser\n",
    "\n",
    "You've likely made your own fasta parser by now, so I won't spend a lot of time\n",
    "here. The basic idea is similar to the gff parser: there are two kinds of \n",
    "sections: header lines and sequence lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fasta(fasta_file_object) -> dict:\n",
    "    \"\"\"Reads fasta data from a file object and returns data as a dictionary\n",
    "    \n",
    "    Parameters:\n",
    "    ---\n",
    "    fasta_file_object: file object\n",
    "        A(n already opened) file object\n",
    "\n",
    "    Return:\n",
    "    ---\n",
    "    dict\n",
    "        A dictionary with key=sequence label; value=sequence\n",
    "    \"\"\"\n",
    "\n",
    "    fasta = {}\n",
    "    \n",
    "    for line in fasta_file_object:\n",
    "        clean_line = line.strip()\n",
    "\n",
    "        # Skip empty lines\n",
    "        if clean_line == \"\":\n",
    "            continue\n",
    "\n",
    "        if clean_line[0] == '>':\n",
    "            # [DO SOMETHING WITH A HEADER LINE]\n",
    "            continue\n",
    "        else:\n",
    "            # [DO SOMETHING WITH A SEQUENCE LINE]\n",
    "            continue\n",
    "\n",
    "    return fasta\n",
    "\n",
    "fasta_data, annotation_data, strand_data = gff_parser(\"Catharanthus.gff3\")\n",
    "\n",
    "for label, seq in fasta_data.items():\n",
    "    print(label, len(seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STOP** ✋ Can you finish the fasta parser yourself?\n",
    "\n",
    "These are the values you should have if you run the previous cells:\n",
    "\n",
    "```\n",
    "cro_scaffold_3069583 250200\n",
    "cro_scaffold_3066516 209353\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "Ok, let's continue!\n",
    "\n",
    "If we have a sequence line: simply add the cleaned line to the sequence list.\n",
    "\n",
    "If we have a label line: we need to convert the subsequence list into a proper\n",
    "string, store it in the final dictionary using the current label, get the new\n",
    "label and reset the subsequence list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fasta(fasta_file_object) -> dict:\n",
    "    \"\"\"Reads fasta data from a file object and returns data as a dictionary\n",
    "    \n",
    "    Parameters:\n",
    "    ---\n",
    "    fasta_file_object: file object\n",
    "        A(n already opened) file object\n",
    "\n",
    "    Return:\n",
    "    ---\n",
    "    dict\n",
    "        A dictionary with key=sequence label; value=sequence\n",
    "    \"\"\"\n",
    "\n",
    "    fasta = {}\n",
    "    label = \"\"\n",
    "    sequence = []\n",
    "    for line in fasta_file_object:\n",
    "        clean_line = line.strip()\n",
    "\n",
    "        # Skip empty lines\n",
    "        if clean_line == \"\":\n",
    "            continue\n",
    "\n",
    "        if clean_line[0] == '>':\n",
    "            # Store current data; Prepare for the next record\n",
    "            fasta[label] = \"\".join(sequence)\n",
    "\n",
    "            label = clean_line[1:]\n",
    "            sequence = []\n",
    "        else:\n",
    "            # Keep adding sequence data\n",
    "            sequence.append(clean_line)\n",
    "\n",
    "    return fasta\n",
    "\n",
    "fasta_data, annotation_data, strand_data = gff_parser(\"Catharanthus.gff3\")\n",
    "\n",
    "for label, seq in fasta_data.items():\n",
    "    print(label, len(seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STOP** ✋ Can you figure out what went wrong?\n",
    "\n",
    "As a reminder, these are the values you should have if you run the previous \n",
    "cells:\n",
    "\n",
    "```\n",
    "cro_scaffold_3069583 250200\n",
    "cro_scaffold_3066516 209353\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "There are other ways of concatenating the subsequences, but the one I used above\n",
    "is fast (see a note about this in the \"On Parsing / Reading the data / Tips and\n",
    "tricks\" module in Brightspace)\n",
    "\n",
    "This works for all the fasta records in the middle of the file, but special \n",
    "considerations need to be taken for the first record (we find a '>' character, \n",
    "but we don't have a previous subsequence list) and the last one (we run out of\n",
    "lines to loop on and we won't be getting another '>' character to indicate we \n",
    "have to store the last record). The final fasta-parsing function would look like\n",
    "this (note that here we could do some extra processing, like making sure all \n",
    "bases are upper case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fasta(fasta_file_object) -> dict:\n",
    "    \"\"\"Reads fasta data from a file object and returns data as a dictionary\n",
    "    \n",
    "    Parameters:\n",
    "    ---\n",
    "    fasta_file_object: file object\n",
    "        A(n already opened) file object\n",
    "\n",
    "    Return:\n",
    "    ---\n",
    "    dict\n",
    "        A dictionary with key=sequence label; value=sequence\n",
    "    \"\"\"\n",
    "\n",
    "    fasta = {}\n",
    "    label = \"\"\n",
    "    sequence = []\n",
    "    for line in fasta_file_object:\n",
    "        clean_line = line.strip()\n",
    "\n",
    "        # Skip empty lines\n",
    "        if clean_line == \"\":\n",
    "            continue\n",
    "\n",
    "        if clean_line[0] == '>':\n",
    "            # We found a header\n",
    "\n",
    "            # This evaluates to False if sequence is an empty list (which will\n",
    "            # happen in the very first line)\n",
    "            if sequence:\n",
    "                fasta[label] = \"\".join(sequence)\n",
    "\n",
    "            label = clean_line[1:]\n",
    "            sequence = []\n",
    "        else:\n",
    "            # Keep adding sequence data\n",
    "            sequence.append(clean_line)\n",
    "\n",
    "    # Handle the last record\n",
    "    fasta[label] = \"\".join(sequence)\n",
    "\n",
    "    return fasta\n",
    "\n",
    "fasta_data, annotation_data, strand_data = gff_parser(\"Catharanthus.gff3\")\n",
    "\n",
    "for label, seq in fasta_data.items():\n",
    "    print(label, len(seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cro_scaffold_3069583 250200\n",
    "cro_scaffold_3066516 209353\n",
    "```\n",
    "\n",
    "Yes, we got it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The annotations parser\n",
    "\n",
    "Now it's time to continue working on parsing the annotation section. The header\n",
    "of this section contains lines starting with the '#' symbol that we can safely\n",
    "ignore (a single '#' represents a comment, but lines starting with double '##' \n",
    "can also contain specific metadata and are called \"pragmas\"). \n",
    "\n",
    "The rest of the lines are easy to parse as they are a regular tab-delimited \n",
    "table. We already discussed which columns we need, so let's get them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gff_parser(filename: str) -> tuple([dict, dict]):\n",
    "    \"\"\"Parses a GFF3 file\n",
    "    \n",
    "    Parameters:\n",
    "    ---\n",
    "    filename: str\n",
    "        Name of the GFF3 file\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    A tuple with two elements:\n",
    "        dict: key=contig label, value=a DNA string\n",
    "        dict: key=transcript label, value=a list of tuples representing the\n",
    "            coordinates of each CDS\n",
    "    \"\"\"\n",
    "\n",
    "    fasta = {}\n",
    "    annotation = {}\n",
    "    strand = {}\n",
    "\n",
    "    # parsing algorithm\n",
    "    with open(filename) as gff:\n",
    "        for line in gff:\n",
    "            if line.startswith(\"##FASTA\"):\n",
    "                # Launch a function that parses the fasta section\n",
    "                fasta = parse_fasta(gff)\n",
    "            else:\n",
    "                # Ignore comments and \"pragmas\"\n",
    "                if line[0] == '#':\n",
    "                    continue\n",
    "\n",
    "                # Get all data from line\n",
    "                columns = line.strip().split(\"\\t\")\n",
    "                contig_label = columns[0]\n",
    "                feature_type = columns[2]\n",
    "                start = columns[3]\n",
    "                end = columns[4]\n",
    "                strand_symbol = columns[6]\n",
    "                # the transcript ID needs more cleaning\n",
    "                transcript_label = columns[8].partition(\"Parent=\")[2].split(\";\")[0]\n",
    "\n",
    "                # ignore all features except CDS\n",
    "                if feature_type != \"CDS\":\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "    return fasta, annotation, strand\n",
    "\n",
    "fasta_data, annotation_data, strand_data = gff_parser(\"Catharanthus.gff3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STOP** ✋ We already discussed which data structures to use. Can you modify \n",
    "the above function to populate `annotation_data`? Try it out and run the next\n",
    "cell, which should print `85393\t85925`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(annotation_data['cro_scaffold_3069583']['CRO_T020528'][1])\n",
    "except KeyError:\n",
    "    print(\"Data structure incomplete...\")\n",
    "except IndexError:\n",
    "    print(\"Data structure incomplete...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "Ok, let's populate the data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gff_parser(filename: str) -> tuple([dict, dict]):\n",
    "    \"\"\"Parses a GFF3 file\n",
    "    \n",
    "    Parameters:\n",
    "    ---\n",
    "    filename: str\n",
    "        Name of the GFF3 file\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    A tuple with two elements:\n",
    "        dict: key=contig label, value=a DNA string\n",
    "        dict: key=transcript label, value=a list of tuples representing the\n",
    "            coordinates of each CDS\n",
    "    \"\"\"\n",
    "\n",
    "    fasta = {}\n",
    "    annotation = {}\n",
    "    strand = {}\n",
    "\n",
    "    # parsing algorithm\n",
    "    with open(filename) as gff:\n",
    "        for line in gff:\n",
    "            if line.startswith(\"##FASTA\"):\n",
    "                # Launch a function that parses the fasta section\n",
    "                fasta = parse_fasta(gff)\n",
    "            else:\n",
    "                # Ignore comments and \"pragmas\"\n",
    "                if line[0] == '#':\n",
    "                    continue\n",
    "\n",
    "                # Get all data from line\n",
    "                columns = line.strip().split(\"\\t\")\n",
    "                contig_label = columns[0]\n",
    "                feature_type = columns[2]\n",
    "                start = int(columns[3]) - 1 # Convert to 0-based index!\n",
    "                end = int(columns[4]) - 1\n",
    "                strand_symbol = columns[6]\n",
    "                # the transcript ID needs more cleaning\n",
    "                transcript_label = columns[8].partition(\"Parent=\")[2].split(\";\")[0]\n",
    "\n",
    "                # ignore all features except CDS\n",
    "                if feature_type != \"CDS\":\n",
    "                    continue\n",
    "\n",
    "                # Create entry for contig_label if needed\n",
    "                if contig_label not in annotation:\n",
    "                    annotation[contig_label] = {}\n",
    "\n",
    "                # Initialize list of coordinates if needed\n",
    "                if transcript_label not in annotation[contig_label]:\n",
    "                    annotation[contig_label][transcript_label] = []\n",
    "\n",
    "                # Append new tuple with coordinates\n",
    "                CDS = tuple([start, end])\n",
    "                annotation[contig_label][transcript_label].append(CDS)\n",
    "                \n",
    "                \n",
    "    return fasta, annotation, strand\n",
    "\n",
    "fasta_data, annotation_data, strand_data = gff_parser(\"Catharanthus.gff3\")\n",
    "\n",
    "try:\n",
    "    print(annotation_data['cro_scaffold_3069583']['CRO_T020528'][1])\n",
    "except KeyError:\n",
    "    print(\"Data structure incomplete...\")\n",
    "except IndexError:\n",
    "    print(\"Data structure incomplete...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Here we finished with parsing the .gff file.\n",
    "\n",
    "**STOP** ✋ Can you complete the exercise? Here are the functions that you\n",
    "need to implement:\n",
    "\n",
    "```python\n",
    "def reverse_complement(seq:str) -> str:\n",
    "    \"\"\"Takes a DNA sequence and returns the reverse complement\n",
    "\n",
    "    Parameters:\n",
    "    ---\n",
    "    seq: str\n",
    "        A DNA sequence\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "        str\n",
    "        The reverse complement of the original sequence\n",
    "    \"\"\"\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def translate(seq:str, strand_symbol:str) -> str:\n",
    "    \"\"\"Takes a DNA sequence and returns the translation\n",
    "\n",
    "    Parameters:\n",
    "    ---\n",
    "    seq: str\n",
    "        A DNA sequence\n",
    "    strand_symbol: str\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "        str\n",
    "        A protein sequence\n",
    "    \"\"\"\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def assemble_sequence(contig_sequence:str, CDSlist:list) -> str:\n",
    "    \"\"\"Assembles a complete coding sequence from a list of coordinates\n",
    "\n",
    "    Parameters:\n",
    "    ---\n",
    "    contig_sequence: str\n",
    "        The complete contig DNA sequence\n",
    "    CDSlist: list\n",
    "        A list of tuples representing start/end coordinates\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "        str\n",
    "        A DNA sub-sequence\n",
    "    \"\"\"\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def percentage_coding(fasta_data:dict, annotation_data:dict) -> float:\n",
    "    \"\"\"Calculates which percentage from the total sequence length is coding\n",
    "\n",
    "    Parameters:\n",
    "    ---\n",
    "    fasta_data: dict\n",
    "        Keys=contig label, values=a DNA string\n",
    "    annotation_data: dict\n",
    "        Keys=contig label, values=a dictionary (with keys=transcript label, \n",
    "            values=list of tuples) \n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "        float\n",
    "        The percentage of the total sequence length that is coding\n",
    "    \"\"\"\n",
    "\n",
    "    return\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('jupyter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e37f3e45d263ed4a5c20bd2fc1ed392dd1b4a0c15e8ff73f894789a266bea19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
